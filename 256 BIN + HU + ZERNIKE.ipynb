{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SKBhts6cJBoz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\condapy\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5WJH5edxHh9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 0, 3), (0, 1, 0), (0, 1, 1), (0, 1, 2), (0, 1, 3), (0, 2, 0), (0, 2, 1), (0, 2, 2), (0, 2, 3), (0, 3, 0), (0, 3, 1), (0, 3, 2), (0, 3, 3), (1, 0, 0), (1, 0, 1), (1, 0, 2), (1, 0, 3), (1, 1, 0), (1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 2, 0), (1, 2, 1), (1, 2, 2), (1, 2, 3), (1, 3, 0), (1, 3, 1), (1, 3, 2), (1, 3, 3), (2, 0, 0), (2, 0, 1), (2, 0, 2), (2, 0, 3), (2, 1, 0), (2, 1, 1), (2, 1, 2), (2, 1, 3), (2, 2, 0), (2, 2, 1), (2, 2, 2), (2, 2, 3), (2, 3, 0), (2, 3, 1), (2, 3, 2), (2, 3, 3), (3, 0, 0), (3, 0, 1), (3, 0, 2), (3, 0, 3), (3, 1, 0), (3, 1, 1), (3, 1, 2), (3, 1, 3), (3, 2, 0), (3, 2, 1), (3, 2, 2), (3, 2, 3), (3, 3, 0), (3, 3, 1), (3, 3, 2), (3, 3, 3), (4, 0, 0), (4, 0, 1), (4, 0, 2), (4, 0, 3), (4, 1, 0), (4, 1, 1), (4, 1, 2), (4, 1, 3), (4, 2, 0), (4, 2, 1), (4, 2, 2), (4, 2, 3), (4, 3, 0), (4, 3, 1), (4, 3, 2), (4, 3, 3), (5, 0, 0), (5, 0, 1), (5, 0, 2), (5, 0, 3), (5, 1, 0), (5, 1, 1), (5, 1, 2), (5, 1, 3), (5, 2, 0), (5, 2, 1), (5, 2, 2), (5, 2, 3), (5, 3, 0), (5, 3, 1), (5, 3, 2), (5, 3, 3), (6, 0, 0), (6, 0, 1), (6, 0, 2), (6, 0, 3), (6, 1, 0), (6, 1, 1), (6, 1, 2), (6, 1, 3), (6, 2, 0), (6, 2, 1), (6, 2, 2), (6, 2, 3), (6, 3, 0), (6, 3, 1), (6, 3, 2), (6, 3, 3), (7, 0, 0), (7, 0, 1), (7, 0, 2), (7, 0, 3), (7, 1, 0), (7, 1, 1), (7, 1, 2), (7, 1, 3), (7, 2, 0), (7, 2, 1), (7, 2, 2), (7, 2, 3), (7, 3, 0), (7, 3, 1), (7, 3, 2), (7, 3, 3), (8, 0, 0), (8, 0, 1), (8, 0, 2), (8, 0, 3), (8, 1, 0), (8, 1, 1), (8, 1, 2), (8, 1, 3), (8, 2, 0), (8, 2, 1), (8, 2, 2), (8, 2, 3), (8, 3, 0), (8, 3, 1), (8, 3, 2), (8, 3, 3), (9, 0, 0), (9, 0, 1), (9, 0, 2), (9, 0, 3), (9, 1, 0), (9, 1, 1), (9, 1, 2), (9, 1, 3), (9, 2, 0), (9, 2, 1), (9, 2, 2), (9, 2, 3), (9, 3, 0), (9, 3, 1), (9, 3, 2), (9, 3, 3), (10, 0, 0), (10, 0, 1), (10, 0, 2), (10, 0, 3), (10, 1, 0), (10, 1, 1), (10, 1, 2), (10, 1, 3), (10, 2, 0), (10, 2, 1), (10, 2, 2), (10, 2, 3), (10, 3, 0), (10, 3, 1), (10, 3, 2), (10, 3, 3), (11, 0, 0), (11, 0, 1), (11, 0, 2), (11, 0, 3), (11, 1, 0), (11, 1, 1), (11, 1, 2), (11, 1, 3), (11, 2, 0), (11, 2, 1), (11, 2, 2), (11, 2, 3), (11, 3, 0), (11, 3, 1), (11, 3, 2), (11, 3, 3), (12, 0, 0), (12, 0, 1), (12, 0, 2), (12, 0, 3), (12, 1, 0), (12, 1, 1), (12, 1, 2), (12, 1, 3), (12, 2, 0), (12, 2, 1), (12, 2, 2), (12, 2, 3), (12, 3, 0), (12, 3, 1), (12, 3, 2), (12, 3, 3), (13, 0, 0), (13, 0, 1), (13, 0, 2), (13, 0, 3), (13, 1, 0), (13, 1, 1), (13, 1, 2), (13, 1, 3), (13, 2, 0), (13, 2, 1), (13, 2, 2), (13, 2, 3), (13, 3, 0), (13, 3, 1), (13, 3, 2), (13, 3, 3), (14, 0, 0), (14, 0, 1), (14, 0, 2), (14, 0, 3), (14, 1, 0), (14, 1, 1), (14, 1, 2), (14, 1, 3), (14, 2, 0), (14, 2, 1), (14, 2, 2), (14, 2, 3), (14, 3, 0), (14, 3, 1), (14, 3, 2), (14, 3, 3), (15, 0, 0), (15, 0, 1), (15, 0, 2), (15, 0, 3), (15, 1, 0), (15, 1, 1), (15, 1, 2), (15, 1, 3), (15, 2, 0), (15, 2, 1), (15, 2, 2), (15, 2, 3), (15, 3, 0), (15, 3, 1), (15, 3, 2), (15, 3, 3)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "indexes = list(itertools.product([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],[0,1,2,3],[0,1,2,3]))\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uPYUD4gSHig4"
   },
   "outputs": [],
   "source": [
    "def normalize(values, bounds):\n",
    "    return [bounds['desired']['lower'] + (x - bounds['actual']['lower']) * (bounds['desired']['upper'] - bounds['desired']['lower']) / (bounds['actual']['upper'] - bounds['actual']['lower']) for x in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y4efwXbLHknv"
   },
   "outputs": [],
   "source": [
    "def get_F(h, s, v):\n",
    "    h_norm = normalize(\n",
    "        h,\n",
    "        {'actual': {'lower': 0, 'upper': 179}, 'desired': {'lower': 0, 'upper': 360}}\n",
    "    )\n",
    "    s_norm = normalize(\n",
    "        s,\n",
    "        {'actual': {'lower': 0, 'upper': 255}, 'desired': {'lower': 0, 'upper': 1}}\n",
    "    )\n",
    "    v_norm = normalize(\n",
    "        v,\n",
    "        {'actual': {'lower': 0, 'upper': 255}, 'desired': {'lower': 0, 'upper': 1}}\n",
    "    )\n",
    "    \n",
    "    h_norm = np.array(h_norm).flatten()\n",
    "    s_norm = np.array(s_norm).flatten()\n",
    "    v_norm = np.array(v_norm).flatten()\n",
    "    \n",
    "    h_d = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, 12:0, 13:0, 14:0, 15:0}\n",
    "    s_d = {0:0, 1:0, 2:0, 3:0}\n",
    "    v_d = {0:0, 1:0, 2:0, 3:0}\n",
    "    \n",
    "    for i in range(len(h_norm)):\n",
    "        H = h_norm[i]\n",
    "        ha = math.floor(0.5+(H/22.5))%16\n",
    "        if ha not in h_d:\n",
    "            h_d[ha] = 1\n",
    "        else:\n",
    "            h_d[ha] += 1\n",
    "\n",
    "    for i in range(len(s_norm)):\n",
    "        S = s_norm[i]\n",
    "        sa = S//0.25\n",
    "        if sa not in s_d:\n",
    "            s_d[sa] = 1\n",
    "        else:\n",
    "            s_d[sa] += 1\n",
    "\n",
    "    for i in range(len(v_norm)):\n",
    "        V = v_norm[i]\n",
    "        va = V//0.25\n",
    "        if va not in v_d:\n",
    "            v_d[va] = 1\n",
    "        else:\n",
    "            v_d[va] += 1\n",
    "            \n",
    "    F = np.zeros((256,))\n",
    "    \n",
    "    for i in range(16):\n",
    "        for j in range(4):\n",
    "            for k in range(4):\n",
    "                F[indexes.index((i, j, k))] = h_d[i] + s_d[j] + v_d[k]\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xP0w4dHAJywD"
   },
   "outputs": [],
   "source": [
    "def save_video(fname, key_frames):\n",
    "    count = 0\n",
    "\n",
    "    cur_dir = fname[0:-4]\n",
    "    print(cur_dir)\n",
    "    os.mkdir(cur_dir)\n",
    "\n",
    "    vidcap = cv2.VideoCapture(fname)\n",
    "    success, img = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "\n",
    "    while success:\n",
    "        if count in key_frames:\n",
    "            print(f'{count} in key frame')\n",
    "            cv2.imwrite(cur_dir + \"\\\\\" + str(count) + \".jpg\", img)\n",
    "        success, img = vidcap.read()\n",
    "        count += 1\n",
    "    vidcap.release()\n",
    "\n",
    "def process_video(fname):\n",
    "    \"\"\"\n",
    "        Uses HU AND Zernike moments\n",
    "\n",
    "    \"\"\"\n",
    "    colour_features = []\n",
    "\n",
    "    vidcap = cv2.VideoCapture(fname)\n",
    "    success, img = vidcap.read()\n",
    "\n",
    "    count = 0\n",
    "    while success:\n",
    "        img3 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img2 = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = img2[:,:,0], img2[:,:,1], img2[:,:,2]\n",
    "        F1 = get_F(h, s, v)\n",
    "        F1_norm = normalize(\n",
    "            F1,\n",
    "            {'actual': {'lower': 0, 'upper': 1000000}, 'desired': {'lower': 0, 'upper': 1}}\n",
    "        )\n",
    "        thresh = cv2.threshold(img3, 50, 100, cv2.THRESH_BINARY)[1]\n",
    "        F2 = np.append(mahotas.features.zernike_moments(thresh, 250), cv2.HuMoments(cv2.moments(img3)).flatten())\n",
    "        #print(F)\n",
    "\n",
    "        colour_features.append(np.append(F1_norm, F2))\n",
    "        if(count%25 == 0):\n",
    "            print(f\"{count} images done\")\n",
    "        success, img = vidcap.read()\n",
    "        count += 1\n",
    "    \n",
    "    vidcap.release()\n",
    "        \n",
    "    best_i = 0\n",
    "    best_sc = -1\n",
    "\n",
    "    for i in range(3,21):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=0).fit(colour_features)\n",
    "        sc = silhouette_score(colour_features, kmeans.labels_)\n",
    "        if(sc > best_sc):\n",
    "            best_i = i\n",
    "            best_sc = sc\n",
    "        #print(i, silhouette_score(colour_features, kmeans.labels_))\n",
    "\n",
    "    print(f'Best silhouette score was {best_sc} for k value of {best_i}')\n",
    "\n",
    "    kmeans = KMeans(n_clusters=best_i, random_state=0).fit(colour_features)\n",
    "    cents = kmeans.cluster_centers_\n",
    "\n",
    "    print(len(colour_features), len(kmeans.labels_))\n",
    "\n",
    "    min_dict = {}\n",
    "    min_frame= {}\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        t = np.linalg.norm(colour_features[i]-cents[kmeans.labels_[i]])\n",
    "        if kmeans.labels_[i] not in min_dict:\n",
    "            min_dict[kmeans.labels_[i]] = t\n",
    "            min_frame[kmeans.labels_[i]] = i\n",
    "        else:\n",
    "            if(t < min_dict[kmeans.labels_[i]]):\n",
    "                min_dict[kmeans.labels_[i]] = t\n",
    "                min_frame[kmeans.labels_[i]] = i\n",
    "\n",
    "    print(min_frame)\n",
    "\n",
    "    key_frames = list(min_frame.values())\n",
    "\n",
    "    save_video(fname, key_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "T6QGp6Q7Jkbn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Souvik\\Desktop\\OVPP\\256 BIN_HU_Zernike\\v15.flv\n",
      "0 images done\n",
      "25 images done\n",
      "50 images done\n",
      "75 images done\n",
      "100 images done\n",
      "125 images done\n",
      "150 images done\n",
      "175 images done\n",
      "200 images done\n",
      "225 images done\n",
      "250 images done\n",
      "275 images done\n",
      "300 images done\n",
      "325 images done\n",
      "350 images done\n",
      "375 images done\n",
      "400 images done\n",
      "425 images done\n",
      "450 images done\n",
      "475 images done\n",
      "500 images done\n",
      "525 images done\n",
      "550 images done\n",
      "575 images done\n",
      "600 images done\n",
      "625 images done\n",
      "650 images done\n",
      "675 images done\n",
      "700 images done\n",
      "725 images done\n",
      "750 images done\n",
      "775 images done\n",
      "800 images done\n",
      "825 images done\n",
      "850 images done\n",
      "875 images done\n",
      "900 images done\n",
      "925 images done\n",
      "950 images done\n",
      "975 images done\n",
      "1000 images done\n",
      "1025 images done\n",
      "1050 images done\n",
      "1075 images done\n",
      "1100 images done\n",
      "1125 images done\n",
      "1150 images done\n",
      "1175 images done\n",
      "1200 images done\n",
      "1225 images done\n",
      "1250 images done\n",
      "1275 images done\n",
      "1300 images done\n",
      "1325 images done\n",
      "1350 images done\n",
      "1375 images done\n",
      "Best silhouette score was 0.8241683833578197 for k value of 3\n",
      "1387 1387\n",
      "{2: 1371, 0: 1087, 1: 1333}\n",
      "C:\\Users\\Souvik\\Desktop\\OVPP\\256 BIN_HU_Zernike\\v15\n",
      "Read a new frame:  True\n",
      "1087 in key frame\n",
      "1333 in key frame\n",
      "1371 in key frame\n",
      "C:\\Users\\Souvik\\Desktop\\OVPP\\256 BIN_HU_Zernike\\v16.flv\n",
      "0 images done\n",
      "25 images done\n",
      "50 images done\n",
      "75 images done\n",
      "100 images done\n",
      "125 images done\n",
      "150 images done\n",
      "175 images done\n",
      "200 images done\n",
      "225 images done\n",
      "250 images done\n",
      "275 images done\n",
      "300 images done\n",
      "325 images done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name))\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     36\u001b[0m F1_norm \u001b[38;5;241m=\u001b[39m normalize(\n\u001b[0;32m     37\u001b[0m     F1,\n\u001b[0;32m     38\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1000000\u001b[39m}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesired\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}}\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m thresh \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(img3, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 41\u001b[0m F2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmahotas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzernike_moments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mHuMoments(cv2\u001b[38;5;241m.\u001b[39mmoments(img3))\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#print(F)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m colour_features\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mappend(F1_norm, F2))\n",
      "File \u001b[1;32mE:\\condapy\\lib\\site-packages\\mahotas\\features\\zernike.py:97\u001b[0m, in \u001b[0;36mzernike_moments\u001b[1;34m(im, radius, degree, cm)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (n\u001b[38;5;241m-\u001b[39ml)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 97\u001b[0m             z \u001b[38;5;241m=\u001b[39m \u001b[43m_zernike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mznl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAns\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrac_center\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m             zvalues\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mabs\u001b[39m(z))\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(zvalues)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import cv2\n",
    "for root, dirs, files in os.walk(\"C:\\\\Users\\\\Souvik\\\\Desktop\\\\OVPP\\\\256 BIN_HU_Zernike\", topdown=False):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n",
    "        process_video(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16.01%16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.floor(16.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Color + Shape.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
