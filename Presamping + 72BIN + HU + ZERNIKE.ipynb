{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10b85826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mahotas\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e2c1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 0), (0, 1, 1), (0, 1, 2), (0, 2, 0), (0, 2, 1), (0, 2, 2), (1, 0, 0), (1, 0, 1), (1, 0, 2), (1, 1, 0), (1, 1, 1), (1, 1, 2), (1, 2, 0), (1, 2, 1), (1, 2, 2), (2, 0, 0), (2, 0, 1), (2, 0, 2), (2, 1, 0), (2, 1, 1), (2, 1, 2), (2, 2, 0), (2, 2, 1), (2, 2, 2), (3, 0, 0), (3, 0, 1), (3, 0, 2), (3, 1, 0), (3, 1, 1), (3, 1, 2), (3, 2, 0), (3, 2, 1), (3, 2, 2), (4, 0, 0), (4, 0, 1), (4, 0, 2), (4, 1, 0), (4, 1, 1), (4, 1, 2), (4, 2, 0), (4, 2, 1), (4, 2, 2), (5, 0, 0), (5, 0, 1), (5, 0, 2), (5, 1, 0), (5, 1, 1), (5, 1, 2), (5, 2, 0), (5, 2, 1), (5, 2, 2), (6, 0, 0), (6, 0, 1), (6, 0, 2), (6, 1, 0), (6, 1, 1), (6, 1, 2), (6, 2, 0), (6, 2, 1), (6, 2, 2), (7, 0, 0), (7, 0, 1), (7, 0, 2), (7, 1, 0), (7, 1, 1), (7, 1, 2), (7, 2, 0), (7, 2, 1), (7, 2, 2)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "indexes = list(itertools.product([0,1,2,3,4,5,6,7],[0,1,2],[0,1,2]))\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cc29eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(values, bounds):\n",
    "    return [bounds['desired']['lower'] + (x - bounds['actual']['lower']) * (bounds['desired']['upper'] - bounds['desired']['lower']) / (bounds['actual']['upper'] - bounds['actual']['lower']) for x in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8729f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F(h, s, v):\n",
    "    h_norm = normalize(\n",
    "        h,\n",
    "        {'actual': {'lower': 0, 'upper': 179}, 'desired': {'lower': 0, 'upper': 360}}\n",
    "    )\n",
    "    s_norm = normalize(\n",
    "        s,\n",
    "        {'actual': {'lower': 0, 'upper': 255}, 'desired': {'lower': 0, 'upper': 1}}\n",
    "    )\n",
    "    v_norm = normalize(\n",
    "        v,\n",
    "        {'actual': {'lower': 0, 'upper': 255}, 'desired': {'lower': 0, 'upper': 1}}\n",
    "    )\n",
    "    \n",
    "    h_norm = np.array(h_norm).flatten()\n",
    "    s_norm = np.array(s_norm).flatten()\n",
    "    v_norm = np.array(v_norm).flatten()\n",
    "    \n",
    "    h_d = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}\n",
    "    s_d = {0:0, 1:0, 2:0}\n",
    "    v_d = {0:0, 1:0, 2:0}\n",
    "\n",
    "    for i in range(len(h_norm)):\n",
    "        H = h_norm[i]\n",
    "        ha = None\n",
    "        if H >= 316 or H <= 20:\n",
    "            ha = 0\n",
    "        elif H >= 21 and H <= 40:\n",
    "            ha = 1\n",
    "        elif H >= 41 and H <= 75:\n",
    "            ha = 2\n",
    "        elif H >= 76 and H <= 155:\n",
    "            ha = 3\n",
    "        elif H >= 156 and H <= 190:\n",
    "            ha = 4\n",
    "        elif H >= 191 and H <= 270:\n",
    "            ha = 5\n",
    "        elif H >= 271 and H <= 295:\n",
    "            ha = 6\n",
    "        elif H >= 296 and H <= 315:\n",
    "            ha = 7\n",
    "        if ha not in h_d:\n",
    "            h_d[ha] = 1\n",
    "        else:\n",
    "            h_d[ha] += 1\n",
    "\n",
    "    for i in range(len(s_norm)):\n",
    "        S = s_norm[i]\n",
    "        sa = None\n",
    "        if S >= 0 and S <= 0.2:\n",
    "            sa = 0\n",
    "        elif S > 0.2 and S <= 0.7:\n",
    "            sa = 1\n",
    "        elif S > 0.7 and S <= 1:\n",
    "            sa = 2\n",
    "        if sa not in s_d:\n",
    "            s_d[sa] = 1\n",
    "        else:\n",
    "            s_d[sa] += 1\n",
    "\n",
    "    for i in range(len(v_norm)):\n",
    "        V = v_norm[i]\n",
    "        va = None\n",
    "        if V >= 0 and V <= 0.2:\n",
    "            va = 0\n",
    "        elif V > 0.2 and V <= 0.7:\n",
    "            va = 1\n",
    "        elif V > 0.7 and V <= 1:\n",
    "            va = 2\n",
    "        if va not in v_d:\n",
    "            v_d[va] = 1\n",
    "        else:\n",
    "            v_d[va] += 1\n",
    "            \n",
    "    F = np.zeros((72,))\n",
    "    \n",
    "    for i in range(8):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                F[indexes.index((i, j, k))] = 9*h_d[i] + 3*s_d[j] + v_d[k]\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01db03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video2(fname, frames, key_frames):\n",
    "    count = 0\n",
    "\n",
    "    cur_dir = fname[0:-4]\n",
    "    print(cur_dir)\n",
    "    os.mkdir(cur_dir)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(frames)):\n",
    "        if count in key_frames:\n",
    "            if(cv2.imwrite(cur_dir + \"\\\\\" + str(count) + \".jpg\", frames[i])):\n",
    "                print(cur_dir + \"\\\\\" + str(count) + \".jpg\")\n",
    "        count += 1\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92a8aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(fname, key_frames):\n",
    "    count = 0\n",
    "\n",
    "    cur_dir = fname[0:-4]\n",
    "    print(cur_dir)\n",
    "    os.mkdir(cur_dir)\n",
    "\n",
    "    vidcap = cv2.VideoCapture(fname)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    success, img = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "\n",
    "    while success:\n",
    "        if count in key_frames:\n",
    "            print(f'{count} in key frame')\n",
    "            if(cv2.imwrite(cur_dir + \"\\\\\" + str(count) + \".jpg\", img)):\n",
    "                print(cur_dir + \"\\\\\" + str(count) + \".jpg\")\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "        success, img = vidcap.read()\n",
    "        #print('Read a new frame: ', success)\n",
    "        count += 1\n",
    "    vidcap.release()\n",
    "    \n",
    "    return\n",
    "\n",
    "def presample_video(fname):\n",
    "    vidcap = cv2.VideoCapture(fname)\n",
    "    success, img = vidcap.read()\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    #print(success)\n",
    "    sampling_rate = 1\n",
    "\n",
    "    count = 0\n",
    "    frames = []\n",
    "    frames.append(img)\n",
    "    \n",
    "    while success:\n",
    "        if(count%(int(fps//sampling_rate)) == 0):\n",
    "            frames.append(img)\n",
    "            # print(count)\n",
    "        count += 1\n",
    "        \n",
    "        success, img= vidcap.read()\n",
    "    \n",
    "    vidcap.release()\n",
    "    \n",
    "    return frames\n",
    "        \n",
    "def process_video(fname):\n",
    "    frames = presample_video(fname)\n",
    "    colour_features = []\n",
    "    count = 0\n",
    "    \n",
    "    for frame in frames:\n",
    "        img2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        img3 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        h, s, v = img2[:,:,0], img2[:,:,1], img2[:,:,2]\n",
    "        F1 = get_F(h, s, v)\n",
    "        F1_norm = normalize(\n",
    "            F1,\n",
    "            {'actual': {'lower': 0, 'upper': 1000000}, 'desired': {'lower': 0, 'upper': 1}}\n",
    "        )\n",
    "        thresh = cv2.threshold(img3, 75, 200, cv2.THRESH_BINARY)[1]\n",
    "        F2 = np.append(mahotas.features.zernike_moments(thresh, 250), cv2.HuMoments(cv2.moments(img3)).flatten())\n",
    "        #print(F)\n",
    "        F = np.append(F1_norm, F2)\n",
    "        colour_features.append(F)\n",
    "        if(count%10 == 0):\n",
    "            print(\"{count} images done\".format(count=count))\n",
    "        count += 1\n",
    "        \n",
    "    best_i = 0\n",
    "    best_sc = -1\n",
    "\n",
    "    for i in range(3,21):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=0).fit(colour_features)\n",
    "        sc = silhouette_score(colour_features, kmeans.labels_)\n",
    "        if(sc > best_sc):\n",
    "            best_i = i\n",
    "            best_sc = sc\n",
    "        print(i, silhouette_score(colour_features, kmeans.labels_))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=best_i, random_state=0).fit(colour_features)\n",
    "    cents = kmeans.cluster_centers_\n",
    "\n",
    "    print(len(colour_features), len(kmeans.labels_))\n",
    "\n",
    "    min_dict = {}\n",
    "    min_frame= {}\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        t = np.linalg.norm(colour_features[i]-cents[kmeans.labels_[i]])\n",
    "        if kmeans.labels_[i] not in min_dict:\n",
    "            min_dict[kmeans.labels_[i]] = t\n",
    "            min_frame[kmeans.labels_[i]] = i\n",
    "        else:\n",
    "            if(t < min_dict[kmeans.labels_[i]]):\n",
    "                min_dict[kmeans.labels_[i]] = t\n",
    "                min_frame[kmeans.labels_[i]] = i\n",
    "\n",
    "    print(min_frame)\n",
    "\n",
    "    key_frames = list(min_frame.values())\n",
    "    \n",
    "    save_video2(fname, frames, key_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8027a938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Souvik\\Desktop\\CHECK\\vid1\\ucf1.avi\n",
      "0 images done\n",
      "3 0.41688455385427947\n",
      "4 0.4375848997521425\n",
      "5 0.3667113240152011\n",
      "6 0.30584839575535994\n",
      "7 0.24999995454141624\n",
      "8 0.24999995454141624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Souvik\\AppData\\Local\\Temp\\ipykernel_15320\\1792267015.py:78: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=i, random_state=0).fit(colour_features)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=8 should be >= n_clusters=9.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name))\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     75\u001b[0m best_sc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[1;32m---> 78\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolour_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     sc \u001b[38;5;241m=\u001b[39m silhouette_score(colour_features, kmeans\u001b[38;5;241m.\u001b[39mlabels_)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(sc \u001b[38;5;241m>\u001b[39m best_sc):\n",
      "File \u001b[1;32mE:\\condapy\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1146\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m \n\u001b[0;32m   1114\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1138\u001b[0m     X,\n\u001b[0;32m   1139\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1144\u001b[0m )\n\u001b[1;32m-> 1146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m   1148\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mE:\\condapy\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:947\u001b[0m, in \u001b[0;36mKMeans._check_params\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# n_clusters\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters:\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be >= n_clusters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# tol\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tol \u001b[38;5;241m=\u001b[39m _tolerance(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol)\n",
      "\u001b[1;31mValueError\u001b[0m: n_samples=8 should be >= n_clusters=9."
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(\"C:\\\\Users\\\\Souvik\\\\Desktop\\\\CHECK\\\\vid1\", topdown=False):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n",
    "        process_video(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3e310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e78af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
