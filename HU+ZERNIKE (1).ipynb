{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HU+ZERNIKE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install numpy --upgrade"
      ],
      "metadata": {
        "id": "aCSOloyYOrW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mahotas"
      ],
      "metadata": {
        "id": "fEElkrKVOxx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mahotas"
      ],
      "metadata": {
        "id": "l7YWA6tZO0oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "fukDJNvpO3wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_video(fname, key_frames):\n",
        "    count = 0\n",
        "\n",
        "    cur_dir = fname[0:-4]\n",
        "    print(cur_dir)\n",
        "    os.mkdir(cur_dir)\n",
        "\n",
        "    vidcap = cv2.VideoCapture(fname)\n",
        "    success, img = vidcap.read()\n",
        "    print('Read a new frame: ', success)\n",
        "\n",
        "    while success:\n",
        "        if count in key_frames:\n",
        "            print(f'{count} in key frame')\n",
        "            cv2.imwrite(cur_dir + \"\\\\\" + str(count) + \".jpg\", img)\n",
        "        success, img = vidcap.read()\n",
        "        count += 1\n",
        "    vidcap.release()\n",
        "    \n",
        "    return\n",
        "\n",
        "def process_video(fname):\n",
        "    \"\"\"\n",
        "        Uses Hu and Zernike moments\n",
        "\n",
        "    \"\"\"\n",
        "    shape_features = []\n",
        "\n",
        "    vidcap = cv2.VideoCapture(fname)\n",
        "    success, img = vidcap.read()\n",
        "\n",
        "    count = 0\n",
        "    while success:\n",
        "        img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        thresh = cv2.threshold(img2, 75, 200, cv2.THRESH_BINARY)[1]\n",
        "        F = np.append(mahotas.features.zernike_moments(thresh, 250), cv2.HuMoments(cv2.moments(img2)).flatten())\n",
        "        #print(F)\n",
        "        shape_features.append(F)\n",
        "        if(count%25 == 0):\n",
        "            print(\"{count} images done\".format(count=count))\n",
        "        success, img = vidcap.read()\n",
        "        count += 1\n",
        "    \n",
        "    vidcap.release()\n",
        "        \n",
        "    best_i = 0\n",
        "    best_sc = -1\n",
        "\n",
        "    for i in range(8,9):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=0).fit(shape_features)\n",
        "        sc = silhouette_score(shape_features, kmeans.labels_)\n",
        "        if(sc > best_sc):\n",
        "            best_i = i\n",
        "            best_sc = sc\n",
        "        #print(i, silhouette_score(shape_features, kmeans.labels_))\n",
        "\n",
        "    print(f'Best silhouette score was {best_sc} for k value of {best_i}')\n",
        "\n",
        "    kmeans = KMeans(n_clusters=best_i, random_state=0).fit(shape_features)\n",
        "    cents = kmeans.cluster_centers_\n",
        "\n",
        "    print(len(shape_features), len(kmeans.labels_))\n",
        "\n",
        "    min_dict = {}\n",
        "    min_frame= {}\n",
        "    for i in range(len(kmeans.labels_)):\n",
        "        t = np.linalg.norm(shape_features[i]-cents[kmeans.labels_[i]])\n",
        "        if kmeans.labels_[i] not in min_dict:\n",
        "            min_dict[kmeans.labels_[i]] = t\n",
        "            min_frame[kmeans.labels_[i]] = i\n",
        "        else:\n",
        "            if(t < min_dict[kmeans.labels_[i]]):\n",
        "                min_dict[kmeans.labels_[i]] = t\n",
        "                min_frame[kmeans.labels_[i]] = i\n",
        "\n",
        "    print(min_frame)\n",
        "\n",
        "    key_frames = list(min_frame.values())\n",
        "\n",
        "    save_video(fname, key_frames)"
      ],
      "metadata": {
        "id": "BivcS_GAO3tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "\n",
        "import cv2\n",
        "for root, dirs, files in os.walk(\"F:\\\\UCF101_2\\\\UCF-101\\\\ApplyEyeMakeup\", topdown=False):\n",
        "    for name in files:\n",
        "        print(os.path.join(root, name))\n",
        "        process_video(os.path.join(root, name))"
      ],
      "metadata": {
        "id": "B6KKvgIjO3qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e_7PT_EmO3ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BsjONeUPO3kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IPuPyKZCO3h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j1F9ofSmO3fC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}